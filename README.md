# Disaster-Tweet-Prediction-Using-NLP
## 1. Introduction 
The main objective of this project is to solve this problem by inducing the use of Natural Language Processing (NLP) methodologies to accurately predict disaster-related tweets from social media platforms. This is because NLP is a powerful artificial intelligence tool with much textual data. As a result, the use of NPL algorithms helps to detect disaster-alerting tweets from among the noisy dataset of media tweets. 

## 2. Dataset
1. https://drive.google.com/drive/folders/1y80ILdRRYI7oQ1EGeevLnBwjYwrXLhkU?usp=drive_link
2. Open this link and go back to the folder.
3. This will allow us to link between Dataset and Google Colab.

## 3. Why this Dataset? 
The dataset used in this project is from the Kaggle competition. It is divided into two files (train – the training set, test – the test set, and sample_submission.csv - a sample submission file in the correct format)

## 4. How to Use?
1. Disaster Tweet Prediction Using NLP
https://github.com/RaviPrasadGrandhi/Disaster-Tweet-Prediction-Using-NLP/blob/main/Disaster_Tweets_Prediction%20v1.1.ipynb
2. Each of the notebook files must be open using google colab and they should be run independently after adding the shortcut of provided dataset in the google drive.
https://drive.google.com/drive/folders/1y80ILdRRYI7oQ1EGeevLnBwjYwrXLhkU?usp=drive_link

## 5. Results
This section discusses the results obtained from the training and evaluation of the BERT model for disaster tweet prediction. The BERT model shows a decreasing trend in training loss across three epochs, indicating it is effectively learning to predict disaster-related tweets from the training data. 

## 6. Created by 

1. Ravi Prasad Grandhi
2. Dharanidhar Manne
